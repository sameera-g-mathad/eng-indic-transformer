{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e546e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Literal\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from en_indic_transformer import Transformer, Tokenizer, Trainer, TranslationDataLoader, TranslationDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c1b5a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a68fbbc",
   "metadata": {},
   "source": [
    "Specify the home_dir for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "764305f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/sameergururajmathad/eng-indic-transformer')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_dir = Path().absolute().parent\n",
    "home_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdaffa6",
   "metadata": {},
   "source": [
    "Create a various values to use for the rest of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb8b453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = Tokenizer('gpt2' {'<|english|>','<|hindi|>', '<|kannada|>' }) # adding kannada for later\n",
    "corpus_save_dir = home_dir / 'tokenizer'\n",
    "tokenizer = Tokenizer(str(corpus_save_dir/'tokenizer.model')) # uses sentence-piece tokenizer\n",
    "src_prepend_value = '<|english|>'\n",
    "target_prepend_value = '<|hindi|>'\n",
    "\n",
    "batch_size = 16\n",
    "random_seed = 42 # for reproducibility\n",
    "device: Literal['cpu', 'cuda'] = 'cuda' if torch.cuda.is_available() else 'cpu' # device for training.\n",
    "\n",
    "# apply random_seed\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "\n",
    "# transformer details\n",
    "context_length = 1024 # changed from 3000\n",
    "vocab_size = tokenizer.n_vocab # since using gpt2 tokenizer\n",
    "emb_dim = 512\n",
    "enc_layers = 2\n",
    "dec_layers = 2\n",
    "num_heads = 16\n",
    "dropout = 0.1\n",
    "bias = False\n",
    "\n",
    "# training details\n",
    "epochs = 10\n",
    "lr = 1e-5 # change.\n",
    "\n",
    "# data\n",
    "train_frac = 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "272ac497",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = home_dir / 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7e255bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_hindi_csv = data_dir / 'en_hindi.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f2c2159",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_hindi_df = pd.read_csv(en_hindi_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25202c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When it is said to him: 'Fear Allah' egotism t...</td>\n",
       "      <td>और जब उससे कहा जाता है, \"अल्लाह से डर\", तो अहं...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This profile exists already.</td>\n",
       "      <td>यह प्रोफ़ाइल पहले से ही है.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Halo with Ornamental Borde</td>\n",
       "      <td>विवरण: एक पारंपरिक कमल के फूल के साथ पत्थर की ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and the jinn We had created before from flamin...</td>\n",
       "      <td>और हम ही ने जिन्नात को आदमी से (भी) पहले वे धु...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ladies and Gentlemen, the Government of India ...</td>\n",
       "      <td>शहरीकरण की तेज गति के साथ अवसंरचना और सेवाओं क...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780681</th>\n",
       "      <td>Gaja cyclone in Tamil Nadu on 16.11.2018</td>\n",
       "      <td>तमिलनाडू में गजा चक्रवात - 16.11.2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780682</th>\n",
       "      <td>PRESIDENT OF INDIA APPOINTS GOVERNORS</td>\n",
       "      <td>भारत के राष्ट्रपति ने राज्यपालों की नियुक्ति की</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780683</th>\n",
       "      <td>is a phenomenon that 's been promised</td>\n",
       "      <td>एक ऐसी घटना है, जिसकी संभावना दशकों तक</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780684</th>\n",
       "      <td>Move waste to stock</td>\n",
       "      <td>बेकार को भण्डार में ले जाएँ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780685</th>\n",
       "      <td>If 19th century was the century of empires and...</td>\n",
       "      <td>जहां 19वीं सदी साम्राज्यों की तथा20वीं सदी राष...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1780686 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          english_sentence  \\\n",
       "0        When it is said to him: 'Fear Allah' egotism t...   \n",
       "1                             This profile exists already.   \n",
       "2                               Halo with Ornamental Borde   \n",
       "3        and the jinn We had created before from flamin...   \n",
       "4        Ladies and Gentlemen, the Government of India ...   \n",
       "...                                                    ...   \n",
       "1780681           Gaja cyclone in Tamil Nadu on 16.11.2018   \n",
       "1780682              PRESIDENT OF INDIA APPOINTS GOVERNORS   \n",
       "1780683              is a phenomenon that 's been promised   \n",
       "1780684                                Move waste to stock   \n",
       "1780685  If 19th century was the century of empires and...   \n",
       "\n",
       "                                            hindi_sentence  \n",
       "0        और जब उससे कहा जाता है, \"अल्लाह से डर\", तो अहं...  \n",
       "1                             यह प्रोफ़ाइल पहले से ही है.   \n",
       "2        विवरण: एक पारंपरिक कमल के फूल के साथ पत्थर की ...  \n",
       "3        और हम ही ने जिन्नात को आदमी से (भी) पहले वे धु...  \n",
       "4        शहरीकरण की तेज गति के साथ अवसंरचना और सेवाओं क...  \n",
       "...                                                    ...  \n",
       "1780681              तमिलनाडू में गजा चक्रवात - 16.11.2018  \n",
       "1780682    भारत के राष्ट्रपति ने राज्यपालों की नियुक्ति की  \n",
       "1780683            एक ऐसी घटना है, जिसकी संभावना दशकों तक   \n",
       "1780684                        बेकार को भण्डार में ले जाएँ  \n",
       "1780685  जहां 19वीं सदी साम्राज्यों की तथा20वीं सदी राष...  \n",
       "\n",
       "[1780686 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_hindi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0c5364",
   "metadata": {},
   "source": [
    "There are 1786788 rows in the dataset. Use train_len rows for training and remaining for validation. I am running on cpu. Will use gpu later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b47d188",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int(train_frac * len(en_hindi_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a11f2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = en_hindi_df.iloc[:train_len,:]\n",
    "test_df = en_hindi_df.iloc[train_len: :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b9643a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When it is said to him: 'Fear Allah' egotism t...</td>\n",
       "      <td>और जब उससे कहा जाता है, \"अल्लाह से डर\", तो अहं...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This profile exists already.</td>\n",
       "      <td>यह प्रोफ़ाइल पहले से ही है.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Halo with Ornamental Borde</td>\n",
       "      <td>विवरण: एक पारंपरिक कमल के फूल के साथ पत्थर की ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and the jinn We had created before from flamin...</td>\n",
       "      <td>और हम ही ने जिन्नात को आदमी से (भी) पहले वे धु...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ladies and Gentlemen, the Government of India ...</td>\n",
       "      <td>शहरीकरण की तेज गति के साथ अवसंरचना और सेवाओं क...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    english_sentence  \\\n",
       "0  When it is said to him: 'Fear Allah' egotism t...   \n",
       "1                       This profile exists already.   \n",
       "2                         Halo with Ornamental Borde   \n",
       "3  and the jinn We had created before from flamin...   \n",
       "4  Ladies and Gentlemen, the Government of India ...   \n",
       "\n",
       "                                      hindi_sentence  \n",
       "0  और जब उससे कहा जाता है, \"अल्लाह से डर\", तो अहं...  \n",
       "1                       यह प्रोफ़ाइल पहले से ही है.   \n",
       "2  विवरण: एक पारंपरिक कमल के फूल के साथ पत्थर की ...  \n",
       "3  और हम ही ने जिन्नात को आदमी से (भी) पहले वे धु...  \n",
       "4  शहरीकरण की तेज गति के साथ अवसंरचना और सेवाओं क...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d13d6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1602617</th>\n",
       "      <td>I know you can 't read that.</td>\n",
       "      <td>मैं जानता हूँ कि तुम कि पढ़ा नहीं कर सकते।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602618</th>\n",
       "      <td>&amp; File name:</td>\n",
       "      <td>फ़ाइल नामः (F) cd track number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602619</th>\n",
       "      <td>CLICK HERE to see the latest tender notice</td>\n",
       "      <td>नवीनतम निविदा सूचना देखने के लिए यहाँ क्लिक कर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602620</th>\n",
       "      <td>In this globalized and highly competitive worl...</td>\n",
       "      <td>इसीलिए वैश्वीकरण और स्पर्धा के इस दौर में भी ह...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602621</th>\n",
       "      <td>And if he is one of those on the right hand,</td>\n",
       "      <td>और यदि वह भाग्यशालियों में से है,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          english_sentence  \\\n",
       "1602617                       I know you can 't read that.   \n",
       "1602618                                       & File name:   \n",
       "1602619         CLICK HERE to see the latest tender notice   \n",
       "1602620  In this globalized and highly competitive worl...   \n",
       "1602621       And if he is one of those on the right hand,   \n",
       "\n",
       "                                            hindi_sentence  \n",
       "1602617        मैं जानता हूँ कि तुम कि पढ़ा नहीं कर सकते।   \n",
       "1602618                     फ़ाइल नामः (F) cd track number  \n",
       "1602619  नवीनतम निविदा सूचना देखने के लिए यहाँ क्लिक कर...  \n",
       "1602620  इसीलिए वैश्वीकरण और स्पर्धा के इस दौर में भी ह...  \n",
       "1602621                 और यदि वह भाग्यशालियों में से है,   "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9264b6aa",
   "metadata": {},
   "source": [
    "Create lists of source and target sentences for training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24b4c41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "source_train = train_df['english_sentence'].tolist()\n",
    "target_train = train_df['hindi_sentence'].tolist()\n",
    "\n",
    "# test\n",
    "source_test = test_df['english_sentence'].tolist()\n",
    "target_test = test_df['hindi_sentence'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67791a11",
   "metadata": {},
   "source": [
    "Create training and testing data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc142909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset\n",
    "train_dataset = TranslationDataset(src=source_train, target=target_train,tokenizer=tokenizer, src_prepend_value=src_prepend_value, target_prepend_value=target_prepend_value, max_length=context_length)\n",
    "\n",
    "# test dataset\n",
    "test_dataset = TranslationDataset(src=source_test, target=target_test,tokenizer=tokenizer, src_prepend_value=src_prepend_value, target_prepend_value=target_prepend_value, max_length=context_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d2239d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_val = tokenizer.get_piece_id('<|endoftext|>')\n",
    "ignore_index = -100\n",
    "# train dataloader\n",
    "train_dataloader = TranslationDataLoader(train_dataset, batch_size=batch_size, shuffle=True, pad_val=pad_val, ignore_index=ignore_index)\n",
    "\n",
    "# test dataloader\n",
    "test_dataloader = TranslationDataLoader(test_dataset, batch_size=batch_size, shuffle=True, pad_val=pad_val, ignore_index=ignore_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfc9ad5",
   "metadata": {},
   "source": [
    "set aside a input for inference later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5b3b28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iter(test_dataloader)\n",
    "sample_batch = next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5b2ec7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<|english|> socialisation of banks<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|hindi|>',\n",
       " '<|hindi|> बैंकों का समाजीकरण<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer.decode(sample_batch[0][0])\n",
    "target = tokenizer.decode(sample_batch[1][0][:1]) # take the starting token for now.\n",
    "actual_target = tokenizer.decode(sample_batch[1][0]) # take the starting token for now.\n",
    "\n",
    "inputs, target, actual_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6360deec",
   "metadata": {},
   "source": [
    "Create the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29758699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (token_embeddings): Embedding(50000, 512)\n",
       "    (pos_embeddings): Embedding(1024, 512)\n",
       "    (encoder_layers): ModuleList(\n",
       "      (0-1): 2 x EncoderLayer(\n",
       "        (mlp): MLP(\n",
       "          (mlp): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (attn): MultiHeadAttention(\n",
       "          (wq): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (wk): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (wv): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (norm2): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (token_embeddings): Embedding(50000, 512)\n",
       "    (pos_embeddings): Embedding(1024, 512)\n",
       "    (decoder_layers): ModuleList(\n",
       "      (0-1): 2 x DecoderLayer(\n",
       "        (mlp): MLP(\n",
       "          (mlp): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (attn): MultiHeadAttention(\n",
       "          (wq): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (wk): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (wv): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (c_attn): MultiHeadAttention(\n",
       "          (wq): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (wk): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (wv): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm1): LayerNorm()\n",
       "        (norm2): LayerNorm()\n",
       "        (norm3): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (final_layer): Linear(in_features=512, out_features=50000, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(random_seed) # needed to get same weights for reproducibility\n",
    "model = Transformer(vocab_size=vocab_size, context_length=context_length, emb_dim=emb_dim, enc_layers=enc_layers, dec_layers=dec_layers, num_heads=num_heads,dropout=dropout, bias=bias)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29539c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92549120"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb738f8",
   "metadata": {},
   "source": [
    "Create a optimizer and loss function\n",
    "\n",
    "Using Adam optimizer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e287f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f5c2cf",
   "metadata": {},
   "source": [
    "### Create the trainer instance for training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d745e5db",
   "metadata": {},
   "source": [
    "##### create a path to save model checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b228a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_dir = home_dir / 'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0401969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "541754f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The path do not exist yet.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=model, loss_fn=loss_fn, optimizer=optimizer, tokenizer=tokenizer, save_path= model_checkpoint_dir / 'transformer.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55e7ce6",
   "metadata": {},
   "source": [
    "predict method will be invoked by the trainer after `batch_size_to_predict` batches are trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6702f35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10016"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batches = len(train_dataloader)\n",
    "batch_size_to_predict = int(train_batches * 0.1) # every 10% of the batches\n",
    "batch_size_to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "769a3d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train(train_dataloader=train_dataloader, test_dataloader=test_dataloader, epochs=epochs, device=device, predict_input=inputs, target_prefix=target, actual_target=actual_target, batch_size_to_predict=batch_size_to_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
